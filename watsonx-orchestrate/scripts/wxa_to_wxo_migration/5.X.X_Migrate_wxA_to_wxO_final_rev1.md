# watsonx Assistant (wxA) to watsonx Orchestrate (wxO) Migration 

## Migration: Data that will not migrate

- **Conversation logs (in ElasticSearch)**
  - They get deleted automatically after 30/90 days
  - Can be downloaded via API
- **Activity log (in Postgres)**
  - Can be downloaded via API
- **Tooling preferences (in Redis)**
- **Webchat chat history (in Redis)**

## These features are not in wxO

- Intent conflict detection
- Search & conversational search with Discovery
- BYOK
- Fine-grained access control
- Voice gateway

**Note:** The migration procedure can only be used to **migrate to wxO 5.2.0 or to wxO 5.2.1.** Use the appropriate pgmig file to migrate.

## Cluster Preparation (wxA Cluster)

### 1. Create an Additional wxA Instance

* From the Cloud Pak for Data (CPD) UI, create a new wxA instance named `wxo-assistant-de`.

### 2. Log in to the Cluster

```bash
oc login <cluster-url>
```

### 3. Switch to the Assistant Namespace

```bash
oc project <wxA-namespace>
```

### 4. Create Backup Directory

```bash
mkdir backup
cd backup
```

### 5. Export Instance Metadata

* Retrieve the list of wxA instances and save it. 

```bash
oc rsh wa-postgres-16-1 bash -c "psql -U postgres -d conversation_pprd_wa -c \"SELECT tenant_id, instance_id, name, region FROM tenant;\""
```
List only instances that are not deleted
```
oc exec -n cpd wa-postgres-16-1 -- psql -U postgres -d conversation_pprd_wa -c "SELECT tenant_id, instance_id, name, region FROM tenant WHERE deleted IS NOT TRUE ORDER BY name;"
```
* If the postgres pod named wa-postgres-16-1 does not exist, replace it in the command above with the appropriate wa-postgres-16-X pod name from the wa-postgres portgres cluster pod list.
Note: In older versions of watsonX Assistant, the pod names follow the format wa-postgres-X.

* Save the output for reference.

Use the following command to create a file to auto-create orchestrate instances.
```
oc exec -n cpd wa-postgres-16-1 -- psql -U postgres -d conversation_pprd_wa -c "SELECT CASE WHEN region = 'monitoring' THEN 'monitoring' ELSE name END || ',orchestrate,5.2.2' FROM tenant WHERE deleted IS NOT TRUE AND region IN ('us-south', 'monitoring') ORDER BY CASE WHEN region = 'monitoring' THEN 0 ELSE 1 END, name;" | grep -E "(instance-[0-9]+|monitoring),orchestrate"
```

### 6. Take MCG (Object Storage) Backup

#### 6.1 Set Required Environment Variable

```bash
export PROJECT_CPD_INST_OPERANDS=<namespace where watsonx Assistant is installed>
```

#### 6.2 Install AWS CLI

* Red Hat:

```bash
dnf install awscli -y
```

* macOS:

```bash
brew install awscli
```

#### 6.3 Backup S3 Buckets

```bash
export PYTHONWARNINGS="ignore:Unverified HTTPS request"
oc port-forward -n openshift-storage service/s3 10443:443 &

NOOBAA_ACCESS_KEY=$(oc get secret noobaa-admin -n openshift-storage -o json | jq -r '.data.AWS_ACCESS_KEY_ID | @base64d')
NOOBAA_SECRET_KEY=$(oc get secret noobaa-admin -n openshift-storage -o json | jq -r '.data.AWS_SECRET_ACCESS_KEY | @base64d')

alias s3='AWS_ACCESS_KEY_ID=$NOOBAA_ACCESS_KEY AWS_SECRET_ACCESS_KEY=$NOOBAA_SECRET_KEY aws --endpoint https://localhost:10443 --no-verify-ssl s3'

s3 sync s3://wa-api-prod-wa-v1-${PROJECT_CPD_INST_OPERANDS} ./wa-api-prod-wa-v1-${PROJECT_CPD_INST_OPERANDS}
ls -l ./wa-api-prod-wa-v1-${PROJECT_CPD_INST_OPERANDS} | head -n 50

s3 sync s3://wa-api-prod-wa-v1-${PROJECT_CPD_INST_OPERANDS}-transient ./wa-api-prod-wa-v1-${PROJECT_CPD_INST_OPERANDS}-transient
ls -l ./wa-api-prod-wa-v1-${PROJECT_CPD_INST_OPERANDS}-transient | head -n 50
```

### 7. Take PostgreSQL Backup

#### 7.1 Trigger New Backup Job

```bash
oc create job --from=cronjob/wa-store-cronjob wa-store-cronjob-manual
```

#### 7.2 Wait for Completion

```bash
oc get job wa-store-cronjob-manual
```

Expect:

```
NAME                      STATUS     COMPLETIONS   DURATION   AGE
wa-store-cronjob-manual   Complete   1/1           16s        2m2s
```

### 8. Extract PostgreSQL Backup

* In another terminal, run steps 8.1, 8.2 and 8.3. 

#### 8.1 Identify the CronJob Pod 

```bash
export STORE_CRONJOB_POD=$(oc get pods -l component=store-cronjob --no-headers | awk 'NR==1{print $1}')
echo $STORE_CRONJOB_POD
```

#### 8.2 Enter Debug Pod

```bash
oc debug ${STORE_CRONJOB_POD}
```

#### 8.3 List Backup Files

```bash
ls -l /store-backups/
```

> Identify the most recent `store.dump_YYYYMMDD-TIME` and `auth-encryption-wa_YYYYMMDD-TIME.yaml`.

* While the debug pod is running in the second terminal. Run the following commands in the first terminal.

#### 8.4 Identify Debug Pod

```bash
export STORE_CRONJOB_DEBUG_POD=$(oc get pods | grep debug | awk '{print $1}')
echo ${STORE_CRONJOB_DEBUG_POD}
```

#### 8.5 Export Dump File Name

```bash
export STORE_DUMP_FILE=store.dump_YYYYMMDD-TIME
echo ${STORE_DUMP_FILE}
```

#### 8.6 Copy Dump File

```bash
oc cp ${STORE_CRONJOB_DEBUG_POD}:/store-backups/${STORE_DUMP_FILE} ${STORE_DUMP_FILE}
```

### 9. Backup Encryption Secret

```bash
oc get secret wa-auth-encryption -n ${PROJECT_CPD_INST_OPERANDS} -o yaml > wa-auth-encryption-backup.yaml
```

> Verify the file's content.

### 10. Final Validation

```bash
ls -l store.dump_YYYYMMDD-TIME wa-auth-encryption-backup.yaml
```

### 11. Transfer Backup Files to the wxO cluster

* Create `postgres-backup` and `mcg-backup` folder.
* Upload following files to the `postgres-backup` folder:

  * `pgbackup/store.dump_YYYYMMDD-HHMMSS`
  * `wa-auth-encryption-backup.yaml`

* Upload the following folder and the contents to the `mcg-backup` folder:

  * `wa-api-prod-wa-v1-<namespace>/`
  * `wa-api-prod-wa-v1-<namespace>-transient/`

## wxO Cluster Restore & Migration

### 12. Verify `wxo-assistant-de` watsonx assistant service instance in tje Cloud Pak for Data UI

* If missing, delete the `wo-wa-digitalemployee` secret in the operand namespace, this will create a wxo-assistant-de instance after few minutes.

### 13. Create wxO Instances

* Use the output from step 5.
* Ignore `System` or unnamed `system` region instances.
* Create bdd-test and monitoring wxO instances (these instances won't have their names listed in the output from step 5).
* Create additional wxO instances using the same names as listed in the output (e.g., `instance-1`, `instance-2`).
* Skip the `wxo-assistant-de` instance as we already created it in Step 12.

### 14. Set Environment Variables

```bash
export PROJECT_CPD_INST_OPERATORS=<enter your IBM Software Hub operator project>
export PROJECT_CPD_INST_OPERANDS=<enter your IBM Software Hub operand project>
export BACKUP_DIR=<full path to postgres-backup folder> # Check Step 11
```

### 15. Change to Backup Directory

```bash
cd ${BACKUP_DIR}
```

### 16. Download `pgmig` Tool

* Provide the download path or URL.

### 17. Set Encryption File Environment Variable

```bash
export WA_AUTH_ENCRYPTION_FILE=wa-auth-encryption-backup.yaml
```

### 18. Extract Base64 Encryption Key

```bash
export BASE64_VAL=$(grep authorization_encryption_key ${WA_AUTH_ENCRYPTION_FILE} | awk '{print $2}')
echo $BASE64_VAL
```

### 19. Patch Encryption Secret

```bash
oc patch secret wo-wa-auth-encryption -n ${PROJECT_CPD_INST_OPERANDS} --type=merge -p "{\"data\": {\"authorization_encryption_key\": \"${BASE64_VAL}\"}}"
```

### 20. Retrieve Access Token

```bash
export TOKEN=$(oc get secret zen-service-broker-secret -n ${PROJECT_CPD_INST_OPERANDS} --template={{.data.token}} | base64 --decode)
echo ${TOKEN}
```

### 21. Generate `resourceController.yaml`

```bash
cat <<EOF > resourceController.yaml
accessTokens:
  - ${TOKEN}
host: zen-core-api-svc.${PROJECT_CPD_INST_OPERANDS}
port: 4444
type: orchestrate
EOF
```

### 22. Generate `postgres.yaml`

```bash
oc get secret wo-wa-store-datastore-connection-strings -o jsonpath='{.data.store_vcap_services}' \
| base64 -d \
| jq -r '.["user-provided"][0].credentials | 
"host: \(.host)
port: \(.port)
database: \(.database)
username: \(.username)
su_username: \(.username)
su_password: \(.password)"' > postgres.yaml
```

### 23. Retrieve Postgres Certificate

```bash
oc get secret wo-wa-postgres-16-ca -o jsonpath='{.data.ca\.crt}' | base64 -d | tee ${BACKUP_DIR}/ca.crt | openssl x509 -noout -text
```

### 24. Prepare Pod for Migration

Set POSTGRES_POD variable to one of the pod of `wo-wa-postgres-16` postgres cluster.

```bash
export POSTGRES_POD=wo-wa-postgres-16-1
oc exec -it ${POSTGRES_POD} -- mkdir /controller/tmp/bu
```

### 25. Copy Backup to Pod

```bash
oc rsync ${BACKUP_DIR}/ ${POSTGRES_POD}:/controller/tmp/bu/
```

### 26. Scale Down Services

```bash
oc scale deploy ibm-watson-assistant-operator -n ${PROJECT_CPD_INST_OPERATORS} --replicas=0
oc scale deployment wo-wa-store -n ${PROJECT_CPD_INST_OPERANDS} --replicas=0
```

### 27. Run the Migration Tool

Replace store.dump_YYYYMMDD-TIME in the command below with filename from step 8.5

```bash
oc exec -it ${POSTGRES_POD} /bin/bash

# After your get the shell prompt run following
# Replace store.dump_YYYYMMDD-TIME in the pgmig command with the store.dump file present in the /controller/tmp/bu folder 

export ENABLE_ICP=true
cd /controller/tmp/bu
ls /controller/tmp/bu/store.dump_*
export PG_CA_FILE=/controller/tmp/bu/ca.crt
chmod 755 pgmig
./pgmig --resourceController resourceController.yaml --target postgres.yaml --source store.dump_YYYYMMDD-TIME --force --wxo
```

Map each service instance as prompted.   
* If the instance name is `null`, check more details by pressing "0" and then map it to the "bdd" or "monitoring" instance as appropriate.  
* If the instance name is listed, map it to the instance created with the same name.

Exit the pod after the restore completes.

If you have created mapping file, use the following command
```
./pgmig --resourceController resourceController.yaml --target postgres.yaml --source store.dump_20251125-011455  --wxo --force -m enteredMapping.yaml 
```

where enteredMapping.yaml is in format
```
instance-mappings:
  e10001eb-6272-453a-bb43-3dcf0e765892: 00000000-0000-0000-1764-035503433645
  00000000-0000-0000-1764-032283900524: 00000000-0000-0000-1764-035353588112
  00000000-0000-0000-1764-032327588498: 00000000-0000-0000-1764-035434010712
  00000000-0000-0000-1764-032285027994: 00000000-0000-0000-1764-035361344814
  src: dest
```

### 28. Scale Up Services Post-Migration

```bash
oc scale deploy ibm-watson-assistant-operator -n ${PROJECT_CPD_INST_OPERATORS} --replicas=1
oc scale deployment wo-wa-store -n ${PROJECT_CPD_INST_OPERANDS} --replicas=1
oc rollout restart sts wo-wa-redis-server -n ${PROJECT_CPD_INST_OPERANDS}
```

### 29. Restore MCG Data

#### 29.1 Install AWS CLI

* Red Hat:

```bash
dnf install awscli -y
```

* macOS:

```bash
brew install awscli
```

#### 29.2 Configure Environment

```bash
export BACKUP_DIR=<mcg-backup path> # Check Step 11
export PYTHONWARNINGS="ignore:Unverified HTTPS request"
cd ${BACKUP_DIR}
```

#### 29.3 Port-forward S3 Service

```bash
oc port-forward -n openshift-storage service/s3 10443:443 &
```

#### 29.4 Set S3 Credentials

```bash
NOOBAA_ACCESS_KEY=$(oc get secret noobaa-admin -n openshift-storage -o json | jq -r '.data.AWS_ACCESS_KEY_ID|@base64d')
NOOBAA_SECRET_KEY=$(oc get secret noobaa-admin -n openshift-storage -o json | jq -r '.data.AWS_SECRET_ACCESS_KEY|@base64d')

alias s3='AWS_ACCESS_KEY_ID=$NOOBAA_ACCESS_KEY AWS_SECRET_ACCESS_KEY=$NOOBAA_SECRET_KEY aws --endpoint https://localhost:10443 --no-verify-ssl s3'

export PROJECT_CPD_INST_OPERANDS_WXA_CLUSTER=<namespace where wxA was installed on the original cluster>
export PROJECT_CPD_INST_OPERANDS=<enter your IBM Software Hub operand project>
```

#### 29.5 Restore Data

```bash
s3 mb s3://wa-api-prod-wo-wa-v1-${PROJECT_CPD_INST_OPERANDS} # Bucket may already exist
s3 sync wa-api-prod-wa-v1-${PROJECT_CPD_INST_OPERANDS_WXA_CLUSTER} s3://wa-api-prod-wo-wa-v1-${PROJECT_CPD_INST_OPERANDS}

s3 mb s3://wa-api-prod-wo-wa-v1-${PROJECT_CPD_INST_OPERANDS}-transient # Bucket may already exist
s3 sync wa-api-prod-wa-v1-${PROJECT_CPD_INST_OPERANDS_WXA_CLUSTER}-transient s3://wa-api-prod-wo-wa-v1-${PROJECT_CPD_INST_OPERANDS}-transient
```

### 30. Auto-Retrain Restored Data

Additional details of how to autotrain in this document: https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-backup-data#set-up-retrain-model

```bash
export AUTO_RETRAIN="false"
export CLU_CLEAN_UP="false"
export AUTO_RETRAIN_ALL_CRON_SCHEDULE="0 0 0 * * ? *" # Set it to run 10 minutes after applying the temporary patch listed below.
export AUTO_RETRAIN_ALL_ENABLED="true"
export BATCH_RETRAIN_ALL_SIZE="8"
export WAIT_TIME_BETWEEN_BATCH_RETRAIN_IN_SECONDS_FOR_RETRAIN_ALL="52"
export WAIT_TIME_BETWEEN_TRAININGS_FOR_RETRAIN_ALL="1"
export INSTANCE=wo-wa

cat <<EOF | oc apply -f -
apiVersion: assistant.watson.ibm.com/v1
kind: TemporaryPatch
metadata:
  name: ${INSTANCE}-store-admin-auto-train
  namespace: ${PROJECT_CPD_INST_OPERANDS}
spec:
  apiVersion: assistant.watson.ibm.com/v1
  kind: WatsonAssistantStore
  name: ${INSTANCE}
  patchType: patchStrategicMerge
  patch:
    store-admin:
      deployment:
        spec:
          template:
            spec:
              containers:
              - name: store-admin
                env:
                - name: AUTO_RETRAIN
                  value: "${AUTO_RETRAIN}"
                - name: AUTO_RETRAIN_ALL_CRON_SCHEDULE
                  value: "${AUTO_RETRAIN_ALL_CRON_SCHEDULE}"
                - name: AUTO_RETRAIN_ALL_ENABLED
                  value: "${AUTO_RETRAIN_ALL_ENABLED}"
                - name: BATCH_RETRAIN_ALL_SIZE
                  value: "${BATCH_RETRAIN_ALL_SIZE}"
                - name: WAIT_TIME_BETWEEN_BATCH_RETRAIN_IN_SECONDS_FOR_RETRAIN_ALL
                  value: "${WAIT_TIME_BETWEEN_BATCH_RETRAIN_IN_SECONDS_FOR_RETRAIN_ALL}"
                - name: WAIT_TIME_BETWEEN_TRAININGS_FOR_RETRAIN_ALL
                  value: "${WAIT_TIME_BETWEEN_TRAININGS_FOR_RETRAIN_ALL}"
EOF
```

After a few minutes, the store-admin deployment will be updated with the changes and will automatically retrain the skills. Once all skills are trained, set AUTO_RETRAIN to "false" and reapply the patch.

### 31. Enable Classic IA and Dialog Support

* Create a file with following script and run it.

```bash
#!/bin/bash

# Get the namespace where Watson Orchestrate is installed
NAMESPACE=$(oc get wo -A --no-headers | awk '{print $1}' | head -n 1)

# Check if a namespace was found
if [ -z "$NAMESPACE" ]; then
    echo "Watson Orchestrate is not installed or could not be detected."
    exit 1
fi

# Export the NAMESPACE variable
export NAMESPACE
export INSTANCE=wo
oc patch wo $INSTANCE -n $NAMESPACE --type='merge' -p='{"spec":{"watsonAssistants":{"config":{"configOverrides":{"ui":{"features":{"private":{"ia-wxo-classic-supported": true, "ia-wxo-dialog-supported": true, "ia-wxo-agent-builder-features": true}}}}}}}}'
```
